{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee81150",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=\"AIzaSyAuDcX3jEv2CNO02GlCQM3I4GbAIF1P_iY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d5e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('verdict', 'phishing'), ('risk_level', 'high'), ('confidence', 'high'), ('reasons', 'Homograph domain spoofing, Brand impersonation, Suspicious domain name'), ('evidence', 'paypa1.com (likely using the number \"1\" to impersonate \"l\" in \"paypal\"), Domain name is not the official PayPal domain.')]\n",
      "\n",
      "🔎 Gemini Analysis Result:\n",
      "\n",
      "['v', 'e', 'r', 'd', 'i', 'c', 't', '=', 'p', 'h', 'i', 's', 'h', 'i', 'n', 'g', '\\n', 'r', 'i', 's', 'k', '_', 'l', 'e', 'v', 'e', 'l', '=', 'h', 'i', 'g', 'h', '\\n', 'c', 'o', 'n', 'f', 'i', 'd', 'e', 'n', 'c', 'e', '=', 'h', 'i', 'g', 'h', '\\n', 'r', 'e', 'a', 's', 'o', 'n', 's', '=', 'H', 'o', 'm', 'o', 'g', 'r', 'a', 'p', 'h', ' ', 'd', 'o', 'm', 'a', 'i', 'n', ' ', 's', 'p', 'o', 'o', 'f', 'i', 'n', 'g', ',', ' ', 'B', 'r', 'a', 'n', 'd', ' ', 'i', 'm', 'p', 'e', 'r', 's', 'o', 'n', 'a', 't', 'i', 'o', 'n', ',', ' ', 'S', 'u', 's', 'p', 'i', 'c', 'i', 'o', 'u', 's', ' ', 'd', 'o', 'm', 'a', 'i', 'n', ' ', 'n', 'a', 'm', 'e', '\\n', 'e', 'v', 'i', 'd', 'e', 'n', 'c', 'e', '=', 'p', 'a', 'y', 'p', 'a', '1', '.', 'c', 'o', 'm', ' ', '(', 'l', 'i', 'k', 'e', 'l', 'y', ' ', 'u', 's', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'n', 'u', 'm', 'b', 'e', 'r', ' ', '\"', '1', '\"', ' ', 't', 'o', ' ', 'i', 'm', 'p', 'e', 'r', 's', 'o', 'n', 'a', 't', 'e', ' ', '\"', 'l', '\"', ' ', 'i', 'n', ' ', '\"', 'p', 'a', 'y', 'p', 'a', 'l', '\"', ')', ',', ' ', 'D', 'o', 'm', 'a', 'i', 'n', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'n', 'o', 't', ' ', 't', 'h', 'e', ' ', 'o', 'f', 'f', 'i', 'c', 'i', 'a', 'l', ' ', 'P', 'a', 'y', 'P', 'a', 'l', ' ', 'd', 'o', 'm', 'a', 'i', 'n', '.']\n",
      "\n",
      "💡 Fraud Percentage: 95%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Load API Key\n",
    "# -----------------------------------------------------------\n",
    "def load_gemini_api():\n",
    "    \"\"\"Loads Gemini API key from environment variables.\"\"\"\n",
    "    load_dotenv()\n",
    "    if not key:\n",
    "        print(\"Error: GEMINI_API_KEY not found in environment variables.\")\n",
    "        exit()\n",
    "    genai.configure(api_key=key)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Initialize Gemini Model\n",
    "# -----------------------------------------------------------\n",
    "def get_gemini_model():\n",
    "    \"\"\"Returns a configured Gemini model instance.\"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "        'gemini-2.0-flash',\n",
    "        generation_config={\n",
    "            \"temperature\": 0.2,         # lower = more consistent\n",
    "            \"max_output_tokens\": 512    # limit tokens\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. System Prompt\n",
    "# -----------------------------------------------------------\n",
    "system_prompt = \"\"\"\n",
    "You are an expert cybersecurity analyst with deep knowledge of phishing, scam websites, malicious online activity, \n",
    "and advanced attacks such as homograph (IDN/holographic) domain spoofing.\n",
    "\n",
    "Your role is to carefully analyze the content of a given website (including its text, structure, metadata, and links). \n",
    "Determine whether the website is a phishing attempt or legitimate. \n",
    "\n",
    "Follow these rules strictly:\n",
    "- Base your reasoning on typical phishing patterns (suspicious login forms, misleading links, brand impersonation, urgent warnings).\n",
    "- Always check for homograph/holographic URLs where different Unicode scripts (e.g., Cyrillic, Greek) are used to mimic real domains.\n",
    "- Always explain the reasoning in concise points.\n",
    "- Be objective: if uncertain, classify as \"suspicious\" instead of giving a false \"safe\" verdict.\n",
    "\n",
    "Respond ONLY in this parameterized format (do not add explanations outside this format):\n",
    "\n",
    "verdict=<phishing or legitimate or suspicious>\n",
    "risk_level=<high, medium, or safe>\n",
    "confidence=<high, medium, low>\n",
    "reasons=<comma-separated brief reasons>\n",
    "evidence=<comma-separated concrete evidence snippets from the website>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. Homograph Detector\n",
    "# -----------------------------------------------------------\n",
    "def detect_homograph(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Detects potential homograph (holographic) attacks in a URL \n",
    "    by checking for mixed Unicode scripts in the domain name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        domain_match = re.findall(r\"://([^/]+)/?\", url)\n",
    "        if not domain_match:\n",
    "            return False\n",
    "        domain = domain_match[0]\n",
    "\n",
    "        scripts = set()\n",
    "        for char in domain:\n",
    "            try:\n",
    "                name = unicodedata.name(char)\n",
    "                if \"CYRILLIC\" in name:\n",
    "                    scripts.add(\"CYRILLIC\")\n",
    "                elif \"GREEK\" in name:\n",
    "                    scripts.add(\"GREEK\")\n",
    "                elif \"LATIN\" in name:\n",
    "                    scripts.add(\"LATIN\")\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        # Suspicious if multiple scripts are mixed\n",
    "        return len(scripts) > 1\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. Gemini Analyzer\n",
    "# -----------------------------------------------------------\n",
    "def gemini_analyze(website_content: str, model):\n",
    "    \"\"\"\n",
    "    Analyzes website content for phishing using the configured Gemini model.\n",
    "    Includes robust error handling for API calls and homograph detection.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check for links in the content\n",
    "        urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', website_content)\n",
    "        homograph_flag = False\n",
    "        for url in urls:\n",
    "            if detect_homograph(url):\n",
    "                homograph_flag = True\n",
    "                website_content += f\"\\n\\n[Warning: Suspicious homograph URL detected: {url}]\"\n",
    "\n",
    "        # Generate response from Gemini\n",
    "        response = model.generate_content(\n",
    "            system_prompt + \"\\n\\nWebsite Content:\\n\" + textwrap.dedent(website_content),\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        # Check if blocked\n",
    "        if hasattr(response, \"prompt_feedback\") and response.prompt_feedback.block_reason:\n",
    "            print(f\"⚠️ Content was blocked: {response.prompt_feedback.block_reason.name}\")\n",
    "            return \"Error: Content blocked\"\n",
    "\n",
    "        clean_output = response.text.replace(\"*\", \"\").strip()\n",
    "\n",
    "        # Add homograph flag for clarity\n",
    "        if homograph_flag:\n",
    "            clean_output += \"\\n[Homograph detection triggered]\"\n",
    "\n",
    "        return clean_output\n",
    "\n",
    "    except genai.types.StopCandidateException as e:\n",
    "        print(f\"⚠️ Generation stopped prematurely: {e}\")\n",
    "        return \"Error: Generation stopped\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ An error occurred: {e}\")\n",
    "        return \"Error: API call failed\"\n",
    "def parse_analysis_to_list(output_string: str) -> list:\n",
    "    \"\"\"Parses the Gemini response string into a list of key-value tuples.\"\"\"\n",
    "    if output_string.startswith(\"Error:\"):\n",
    "        return [(\"error\", output_string)]\n",
    "    \n",
    "    # Use a list comprehension for a concise conversion\n",
    "    # It splits each line by the first '=' and strips whitespace from the key/value\n",
    "    result_list = [\n",
    "        (line.split('=', 1)[0].strip(), line.split('=', 1)[1].strip())\n",
    "        for line in output_string.strip().split('\\n')\n",
    "        if '=' in line\n",
    "    ]\n",
    "    return result_list\n",
    "def calculate_fraud_percentage(parsed: list) -> int:\n",
    "    \"\"\"Converts risk_level and confidence into fraud percentage.\"\"\"\n",
    "    mapping = {\n",
    "        (\"high\", \"high\"): 95,\n",
    "        (\"high\", \"medium\"): 80,\n",
    "        (\"high\", \"low\"): 65,\n",
    "        (\"medium\", \"high\"): 55,\n",
    "        (\"medium\", \"medium\"): 40,\n",
    "        (\"medium\", \"low\"): 25,\n",
    "        (\"safe\", \"high\"): 10,\n",
    "        (\"safe\", \"medium\"): 5,\n",
    "        (\"safe\", \"low\"): 2,\n",
    "    }\n",
    "\n",
    "    risk_level = None\n",
    "    confidence = None\n",
    "    for k, v in parsed:\n",
    "        if k == \"risk_level\":\n",
    "            risk_level = v.lower()\n",
    "        elif k == \"confidence\":\n",
    "            confidence = v.lower()\n",
    "\n",
    "    return mapping.get((risk_level, confidence), 50)  # default fallback 50\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. Example Usage\n",
    "# -----------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    load_gemini_api()\n",
    "    model = get_gemini_model()\n",
    "\n",
    "    example_content = \"www.paypa1.com\"\n",
    "\n",
    "    result = gemini_analyze(example_content, model)\n",
    "    parsed = parse_analysis_to_list(result)\n",
    "    print(parsed)\n",
    "    fraud_percentage = calculate_fraud_percentage(parsed)\n",
    "    print(\"\\n🔎 Gemini Analysis Result:\\n\")\n",
    "    print(result)\n",
    "    print(f\"\\n💡 Fraud Percentage: {fraud_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bffb8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing URL: http://google.com ---\n",
      "\n",
      "🔎 Gemini Analysis Result:\n",
      "\n",
      "verdict=legitimate\n",
      "risk_level=safe\n",
      "confidence=high\n",
      "reasons=The domain is google.com, the content and links are consistent with a legitimate Google search page.\n",
      "evidence=Domain is google.com, links point to google.com, standard google search page layout.\n",
      "\n",
      "📈 Fraud Score: 0.00 / 7.5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'percentage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 215\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result_str)\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📈 Fraud Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfraud_score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / 7.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚨 Fraud Risk: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfraud_score\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpercentage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCould not retrieve content. Analysis aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'percentage'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Installation ---\n",
    "# You need to install requests and beautifulsoup4 for this script to work.\n",
    "# pip install requests beautifulsoup4 python-dotenv\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Load API Key\n",
    "# -----------------------------------------------------------\n",
    "def load_gemini_api():\n",
    "    \"\"\"Loads Gemini API key from environment variables.\"\"\"\n",
    "    load_dotenv()\n",
    "    if not key:\n",
    "        print(\"Error: GEMINI_API_KEY not found in environment variables.\")\n",
    "        exit()\n",
    "    genai.configure(api_key=key)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Initialize Gemini Model\n",
    "# -----------------------------------------------------------\n",
    "def get_gemini_model():\n",
    "    \"\"\"Returns a configured Gemini model instance.\"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "        'gemini-2.0-flash',\n",
    "        generation_config={\n",
    "            \"temperature\": 0.2,         # lower = more consistent\n",
    "            \"max_output_tokens\": 512    # limit tokens\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. System Prompt (No Changes)\n",
    "# -----------------------------------------------------------\n",
    "system_prompt = \"\"\"\n",
    "You are an expert cybersecurity analyst with deep knowledge of phishing, scam websites, malicious online activity, \n",
    "and advanced attacks such as homograph (IDN/holographic) domain spoofing.\n",
    "\n",
    "Your role is to carefully analyze the content of a given website (including its text, structure, metadata, and links). \n",
    "Determine whether the website is a phishing attempt or legitimate. \n",
    "\n",
    "Follow these rules strictly:\n",
    "- Base your reasoning on typical phishing patterns (suspicious login forms, misleading links, brand impersonation, urgent warnings).\n",
    "- Always check for homograph/holographic URLs where different Unicode scripts (e.g., Cyrillic, Greek) are used to mimic real domains.\n",
    "- Always explain the reasoning in concise points.\n",
    "- Be objective: if uncertain, classify as \"suspicious\" instead of giving a false \"safe\" verdict.\n",
    "\n",
    "Respond ONLY in this parameterized format (do not add explanations outside this format):\n",
    "\n",
    "verdict=<phishing or legitimate or suspicious>\n",
    "risk_level=<high, medium, or safe>\n",
    "confidence=<high, medium, low>\n",
    "reasons=<comma-separated brief reasons>\n",
    "evidence=<comma-separated concrete evidence snippets from the website>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. Fetch Website Content (New Function)\n",
    "# -----------------------------------------------------------\n",
    "def fetch_website_content(url: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Fetches the content of a URL and extracts visible text and links.\n",
    "    Returns a formatted string for analysis or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract all visible text from the body\n",
    "        text_content = soup.body.get_text(separator=' ', strip=True) if soup.body else \"\"\n",
    "\n",
    "        # Extract all href links\n",
    "        links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "\n",
    "        # Combine the URL, text, and links into a single context for the LLM\n",
    "        full_content = (\n",
    "            f\"URL BEING ANALYZED: {url}\\n\\n\"\n",
    "            f\"VISIBLE TEXT ON PAGE:\\n{text_content}\\n\\n\"\n",
    "            f\"LINKS FOUND ON PAGE:\\n\" + \"\\n\".join(links)\n",
    "        )\n",
    "        return full_content\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. Homograph Detector (No Changes)\n",
    "# -----------------------------------------------------------\n",
    "def detect_homograph(url: str) -> bool:\n",
    "    try:\n",
    "        domain_match = re.findall(r\"://([^/]+)/?\", url)\n",
    "        if not domain_match: return False\n",
    "        domain = domain_match[0]\n",
    "        scripts = set(unicodedata.name(char).split(' ')[0] for char in domain if 'LATIN' not in unicodedata.name(char, ''))\n",
    "        return len(scripts) > 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. Gemini Analyzer (Minor Tweak for Clarity)\n",
    "# -----------------------------------------------------------\n",
    "def gemini_analyze(website_content: str, model):\n",
    "    \"\"\"\n",
    "    Analyzes website content for phishing using the configured Gemini model.\n",
    "    \"\"\"\n",
    "    if not website_content:\n",
    "        return \"Error: No content to analyze.\"\n",
    "    try:\n",
    "        urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', website_content)\n",
    "        homograph_flag = any(detect_homograph(url) for url in urls)\n",
    "\n",
    "        prompt = system_prompt + \"\\n\\nWebsite Content:\\n\" + textwrap.dedent(website_content)\n",
    "        if homograph_flag:\n",
    "            prompt += \"\\n\\n[System Note: Potential homograph characters detected in links.]\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        clean_output = response.text.replace(\"*\", \"\").strip()\n",
    "\n",
    "        return clean_output\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ An error occurred during Gemini analysis: {e}\")\n",
    "        return \"Error: API call failed\"\n",
    "\n",
    "def parse_analysis_to_dict(output_string: str) -> dict:\n",
    "    \"\"\"Parses the Gemini response string into a dictionary.\"\"\"\n",
    "    if output_string.startswith(\"Error:\"):\n",
    "        return {\"error\": output_string}\n",
    "    \n",
    "    analysis_dict = {}\n",
    "    for line in output_string.strip().split('\\n'):\n",
    "        if '=' in line:\n",
    "            key, value = line.split('=', 1)\n",
    "            analysis_dict[key.strip()] = value.strip()\n",
    "    return analysis_dict\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7. Fraud Score Calculator (No Changes)\n",
    "# -----------------------------------------------------------\n",
    "def calculate_fraud_score(analysis_dict: dict) -> dict:\n",
    "    \"\"\"Calculates a fraud score on a scale of 0 to 10.\"\"\"\n",
    "    if \"error\" in analysis_dict:\n",
    "        return {\"score\": 0}\n",
    "\n",
    "    # Internal weights remain the same\n",
    "    risk_weights = {\"high\": 3, \"medium\": 2, \"safe\": 0}\n",
    "    verdict_weights = {\"phishing\": 2, \"suspicious\": 1, \"legitimate\": 0}\n",
    "    confidence_multipliers = {\"high\": 1.5, \"medium\": 1.2, \"low\": 1.0}\n",
    "\n",
    "    risk = analysis_dict.get(\"risk_level\", \"safe\").lower()\n",
    "    verdict = analysis_dict.get(\"verdict\", \"legitimate\").lower()\n",
    "    confidence = analysis_dict.get(\"confidence\", \"low\").lower()\n",
    "\n",
    "    # Calculate the internal score\n",
    "    base_score = risk_weights.get(risk, 0) + verdict_weights.get(verdict, 0)\n",
    "    internal_score = base_score * confidence_multipliers.get(confidence, 1.0)\n",
    "    \n",
    "    # Scale the score to be out of 10 (internal max score is 7.5)\n",
    "    max_internal_score = 7.5\n",
    "    score_out_of_10 = (internal_score / max_internal_score) * 10\n",
    "    \n",
    "    return {\"score\": round(score_out_of_10, 2)}\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 8. Main Execution Block\n",
    "# -----------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    load_gemini_api()\n",
    "    model = get_gemini_model()\n",
    "\n",
    "    # --- Replace this with the URL you want to analyze ---\n",
    "    target_url = \"http://google.com\" \n",
    "    # Example of a potentially suspicious URL to test (use with caution): \"http://example-bank-login.com\"\n",
    "    \n",
    "    print(f\"--- Analyzing URL: {target_url} ---\")\n",
    "    \n",
    "    # 1. Fetch content from the URL\n",
    "    content_to_analyze = fetch_website_content(target_url)\n",
    "    \n",
    "    if content_to_analyze:\n",
    "        # 2. Analyze the fetched content\n",
    "        result_str = gemini_analyze(content_to_analyze, model)\n",
    "        \n",
    "        # 3. Parse and Score the result\n",
    "        result_dict = parse_analysis_to_dict(result_str)\n",
    "        fraud_score = calculate_fraud_score(result_dict)\n",
    "        \n",
    "        print(\"\\n🔎 Gemini Analysis Result:\\n\")\n",
    "        print(result_str)\n",
    "        print(f\"\\n📈 Fraud Score: {fraud_score['score']:.2f} / 10\")\n",
    "        print(f\"🚨 Fraud Risk: {fraud_score['percentage']}%\")\n",
    "    else:\n",
    "        print(\"\\nCould not retrieve content. Analysis aborted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
